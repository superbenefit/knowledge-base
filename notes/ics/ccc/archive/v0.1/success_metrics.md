# Community Exchange: Success Metrics and Evaluation Framework

This document outlines how we'll measure the health, impact, and success of the Community Exchange. Clear metrics help us understand what's working, identify challenges, and make informed decisions as we grow.

## Core Principles for Evaluation

Our evaluation framework is guided by these principles:

1. **Mixed Methods**: Combining quantitative metrics with qualitative stories and feedback
2. **Participatory**: Involving members in defining and assessing success
3. **Learning-Oriented**: Using evaluation to improve, not just to judge
4. **Transparent**: Sharing results openly with all members
5. **Aligned with Values**: Measuring what matters according to our core principles

## Key Metric Categories

We track metrics across six dimensions to ensure a holistic understanding of system health:

### 1. Participation Metrics

**Activity Level**
- Total number of active members
- Percentage of members who have made at least one exchange in the past month
- Number of new members (monthly/quarterly)
- Member retention rate

**Target Metrics for Year 1:**
- Q3 2025: 20 active members, 80% monthly participation
- Q4 2025: 35-40 active members, 75% monthly participation
- Q1 2026: 50-60 active members, 75% monthly participation

**Engagement Equity**
- Distribution of participation across members (identifying concentration or gaps)
- Diversity of participants (demographics, skills, neighborhoods)
- Connection Circle attendance

**Target Metrics for Year 1:**
- No more than 30% of exchanges concentrated among 10% of members
- Demographics of membership reflect community diversity
- 50% average member attendance at Connection Circles

### 2. Exchange Metrics

**Volume**
- Total number of exchanges (monthly/quarterly)
- Total value of exchanges in credits
- Average exchanges per member

**Target Metrics for Year 1:**
- Q3 2025: 30+ total exchanges
- Q4 2025: 100+ total exchanges
- Q1 2026: 200+ total exchanges

**Diversity**
- Types of goods and services exchanged
- Balance between services, goods, and skill sharing
- New commitment types added monthly

**Target Metrics for Year 1:**
- At least 15 different categories of exchanges represented
- Minimum of 40 active commitments in the pool by end of Q3 2025
- 3-5 new commitment types added monthly

### 3. Credit Flow Metrics

**System Balance**
- Total credits in circulation
- Velocity of credit circulation (how quickly credits move through the system)
- Percentage of members at or near credit limits (both upper and lower)

**Target Metrics for Year 1:**
- Credits in circulation remain within 25% of total membership Ã— 5
- Average credits move at least once every two months
- Less than 10% of members at credit limits

**Health Indicators**
- Credit expiration rate (% of credits that expire unused)
- Credit concentration (% of total credits held by top 10% of members)
- Match rate (% of requests that find a match)

**Target Metrics for Year 1:**
- Credit expiration rate below 10%
- No more than 30% of credits concentrated among 10% of members
- 75% match rate for requests

### 4. Community Impact Metrics

**Relationship Building**
- New connections formed (self-reported)
- Strength of relationships (survey measure)
- Community trust level (survey measure)

**Target Metrics for Year 1:**
- Average of 5 new connections per member
- 80% of members report stronger community ties
- Trust level increases quarter over quarter

**Resource Access**
- Value of goods/services accessed that would be inaccessible without the Exchange
- Unmet needs fulfilled through the system
- Resource security improvement (self-reported)

**Target Metrics for Year 1:**
- 50% of members report accessing otherwise inaccessible resources
- 75% of declared high-priority needs are met within the system
- 60% report improved access to essential resources

### 5. System Health Metrics

**Operational Efficiency**
- Time from exchange to credit recording
- Steward workload hours
- Technology reliability and accessibility

**Target Metrics for Year 1:**
- 90% of exchanges recorded within 48 hours
- Average steward workload under 3 hours/week
- 95% technology uptime

**Governance Quality**
- Member satisfaction with decision-making processes
- Participation in governance activities
- Resolution rate for conflicts/issues

**Target Metrics for Year 1:**
- 80% satisfaction with governance
- 30% of members participate in at least one governance activity
- 90% of conflicts successfully resolved

### 6. Growth and Sustainability Metrics

**Expansion**
- New member invitation rate
- Geographic spread of membership
- New circles or nodes forming

**Target Metrics for Year 1:**
- Each founding member invites at least one new member by Q1 2026
- Representation from at least 5 London neighborhoods
- Groundwork for at least 1 additional circle by Q2 2026

**Long-term Viability**
- Steward pipeline health (new stewards in training)
- Resource sustainability (resources required vs. available)
- Innovation rate (new features or improvements implemented)

**Target Metrics for Year 1:**
- At least 3 new stewards in training by Q1 2026
- Resources sufficient for planned activities + 25% buffer
- Quarterly system improvements based on feedback

## Data Collection Methods

We use a mix of methods to gather evaluation data:

### Regular System Monitoring
- Transaction ledger analysis (monthly)
- Credit balance tracking (biweekly)
- Activity pattern analysis (monthly)
- Technology performance metrics (ongoing)

### Member Feedback
- Quarterly member surveys (5-10 minutes, focused on different aspects each quarter)
- Post-exchange micro-feedback (optional 1-2 question pop-ups)
- Exit interviews for departing members
- Suggestion box (physical at events and digital)

### Qualitative Assessment
- Member stories and testimonials (collected at events and online)
- Steward observations and reflections (documented monthly)
- Community check-ins during Connection Circles
- Annual focus groups on specific aspects of the system

### External Perspective
- Annual review by allied solidarity economy initiatives
- Comparisons with similar systems elsewhere
- Expert consultation on specific challenges

## Evaluation Cycle

Our evaluation process follows a regular rhythm:

### Monthly
- **Quick Pulse Check**: Core metrics dashboard review by stewards
- **System Adjustments**: Small tweaks based on emerging patterns
- **Transparency Report**: Brief metrics summary shared with all members

### Quarterly
- **Member Survey**: Rotating focus on different aspects
- **Deep Dive Analysis**: Comprehensive review of all metric categories
- **Improvement Planning**: Identifying 2-3 priority areas for the next quarter
- **Community Discussion**: Review findings at quarterly all-member gathering

### Annually
- **Comprehensive Impact Assessment**: Full analysis across all dimensions
- **Case Studies**: In-depth exploration of system successes and challenges
- **Strategic Planning**: Long-term adjustments based on findings
- **Public Report**: Shareable documentation of learnings and accomplishments

## Using Evaluation Results

Evaluation is only valuable if the results inform action. We commit to:

1. **Transparency**: Sharing findings with all members
2. **Responsiveness**: Making system adjustments based on what we learn
3. **Learning Culture**: Celebrating both successes and "instructive failures"
4. **Documentation**: Recording our journey for our own reference and to share with others
5. **Adaptation**: Evolving our metrics as the system matures

## Year 1 Evaluation Focus Areas

For our first year, we'll give special attention to these evaluation questions:

1. **Accessibility**: Is the system equally accessible to all members? Are there barriers we need to address?
2. **Needs Matching**: How well does the pool of offerings match the community's needs?
3. **Credit Flow**: Is our credit design (limits, expiration, etc.) creating healthy circulation?
4. **Technology Transition**: How effectively are we managing the shift from Google Sheets to Sarafu.Network?
5. **Community Building**: How is the Exchange affecting relationships and social capital?

## Member Role in Evaluation

Every member has a part to play in our evaluation process:

- **Reporting exchanges** promptly and accurately
- **Participating in surveys** and feedback opportunities
- **Sharing stories** about your Exchange experiences
- **Suggesting improvements** based on your observations
- **Reviewing findings** and participating in improvement planning

## Steward Responsibilities for Evaluation

Stewards ensure our evaluation system functions effectively by:

- **Maintaining accurate records** of all exchanges and credit flows
- **Coordinating data collection** activities
- **Analyzing metrics** and identifying patterns
- **Facilitating improvement discussions** based on findings
- **Implementing agreed-upon changes** to the system
- **Documenting learning** for future reference

---

This evaluation framework will evolve as our Community Exchange grows and matures. The stewardship circle will review and update these metrics annually, with input from all members.